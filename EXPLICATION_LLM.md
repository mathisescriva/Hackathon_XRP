# ü§ñ Comment fonctionne l'analyse LLM

## üìã Vue d'ensemble

L'analyse LLM utilise **OpenAI GPT-4o-mini** pour analyser les transcriptions audio et extraire des informations structur√©es sur les shifts de travail.

## üîÑ Flow complet

### 1. Check-in (D√©marrage du shift)

```
Audio ‚Üí AssemblyAI ‚Üí Transcription ‚Üí LLM ‚Üí Analyse
```

**Ce qui se passe :**
1. L'audio est transcrit par AssemblyAI
2. La transcription est envoy√©e √† OpenAI avec un prompt sp√©cialis√©
3. Le LLM analyse et retourne :
   - `job_type` : Type de travail (ex: "childcare", "cleaning", etc.)
   - `notes` : Notes extraites de la transcription

**Prompt utilis√© :** `analyseStartShift`
- Analyse uniquement le check-in
- Extrait le type de travail
- Notes pr√©liminaires

### 2. Check-out (Fin du shift)

```
Audio ‚Üí AssemblyAI ‚Üí Transcription ‚Üí LLM ‚Üí Analyse compl√®te
```

**Ce qui se passe :**
1. L'audio de check-out est transcrit
2. Les DEUX transcriptions (check-in + check-out) sont envoy√©es au LLM
3. Le LLM fait une analyse compl√®te avec :
   - V√©rification de coh√©rence (heures, horaires)
   - D√©tection de probl√®mes
   - Flags de risque et l√©galit√©
   - Confiance dans l'analyse

**Prompt utilis√© :** `analyseShift`
- Analyse compl√®te du shift
- V√©rifie la coh√©rence temporelle
- D√©tecte les violations l√©gales
- Identifie les risques

## üìä Structure de l'analyse LLM

L'analyse retourne un objet JSON avec :

```json
{
  "job_type": "childcare" | "cleaning" | "unknown",
  "notes": "Notes extraites de la transcription",
  "issues": [
    "Probl√®me 1",
    "Probl√®me 2"
  ],
  "risk_flags": [
    "emotional_load",
    "physical_strain"
  ],
  "legal_flags": [
    "overtime_violation",
    "break_violation"
  ],
  "confidence": 0.0 √† 1.0
}
```

### Champs expliqu√©s

- **`job_type`** : Type de travail identifi√©
- **`notes`** : R√©sum√© ou notes importantes
- **`issues`** : Probl√®mes d√©tect√©s (incoh√©rences, etc.)
- **`risk_flags`** : Risques identifi√©s (charge √©motionnelle, etc.)
- **`legal_flags`** : Violations l√©gales potentielles (heures sup, pauses, etc.)
- **`confidence`** : Niveau de confiance de l'analyse (0.0 √† 1.0)

## üéØ Utilisation dans l'application

### Check-in
- Le LLM identifie le type de travail
- Stock√© dans `llm_structured_json` de la work_session

### Check-out
- Analyse compl√®te avec v√©rifications
- D√©tecte les probl√®mes avant validation
- Aide l'employer √† prendre une d√©cision

### Validation
- L'employer peut voir l'analyse LLM
- D√©cide de valider ou refuser selon les flags
- Les flags l√©gaux sont particuli√®rement importants

## üîß Configuration

**Mod√®le utilis√© :** `gpt-4o-mini`
- Rapide et √©conomique
- Suffisant pour l'analyse de shifts
- Peut √™tre chang√© pour `gpt-4` pour plus de pr√©cision

**Temperature :** `0.3`
- Faible temp√©rature = r√©ponses plus coh√©rentes
- Moins de cr√©ativit√©, plus de pr√©cision

**Format :** `json_object`
- Force le LLM √† retourner du JSON valide
- Facilite le parsing

## üìù Prompts utilis√©s

Les prompts sont d√©finis dans `src/config/prompts.ts` :

- **`system.shiftAnalysis`** : Instructions syst√®me pour l'analyse compl√®te
- **`user.shiftAnalysis`** : Prompt utilisateur avec les transcriptions
- **`system.startShift`** : Instructions pour le check-in
- **`user.startShift`** : Prompt pour le check-in

## üêõ Gestion d'erreurs

Si le LLM √©choue :
- Retourne une analyse par d√©faut
- `job_type: "unknown"`
- `confidence: 0.5`
- Pas de flags de risque/l√©galit√©

## üí° Am√©liorations possibles

- Utiliser `gpt-4` pour plus de pr√©cision
- Ajouter des prompts sp√©cifiques par type de travail
- Am√©liorer la d√©tection des violations l√©gales
- Ajouter des checks de coh√©rence temporelle plus stricts

